{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "from jax import numpy as jnp\n",
    "from jax import random\n",
    "from jaxopt import ProjectedGradient\n",
    "from jaxopt.projection import projection_hyperplane\n",
    "\n",
    "# generate metrix [[0, b, ba, ba^2, ..., ba^H-1], [0,0,b,ba, ..., ba^H-2], ...]\n",
    "def generate_matrix(a, b, H):\n",
    "    matrix = jnp.zeros((H+1, H))\n",
    "    for i in range(1, H+1):\n",
    "        for j in range(0, i):\n",
    "            # matrix = jax.ops.index_update(matrix, jax.ops.index[i, j], b * a ** (j - i))\n",
    "            matrix = matrix.at[i, j].set(b * a ** (i -1 - j))\n",
    "    return matrix\n",
    "\n",
    "def get_sigma_eign(eign_values, lam, H, sig):\n",
    "    # Objective function\n",
    "    def objective(params):\n",
    "        return jnp.sum(eign_values/(1+2/lam*eign_values*jnp.exp(params))**2)\n",
    "\n",
    "    # Constraint: x1 + x2 = 1, represented as a hyperplane\n",
    "    def projection_fn(params, hyperparams_proj):\n",
    "        return projection_hyperplane(params, hyperparams=(hyperparams_proj, H*jnp.log(sig)))\n",
    "\n",
    "    # Initialize 'ProjectedGradient' solver\n",
    "    solver = ProjectedGradient(fun=objective, projection=projection_fn)\n",
    "\n",
    "    # Initial parameters\n",
    "    params_init = jnp.zeros(H)\n",
    "\n",
    "    # Define the optimization problem\n",
    "    sol = solver.run(params_init, hyperparams_proj=jnp.ones(H))\n",
    "\n",
    "    # Print the optimal solution\n",
    "    print(\"Optimal Solution: \", sol)\n",
    "\n",
    "    # check if the solution is feasible\n",
    "    o=eign_values\n",
    "    s=jnp.exp(sol.params)\n",
    "    cc = ((o**2)*s)/((1+2/lam*o*s)**3)\n",
    "    print('cc', cc)\n",
    "\n",
    "    return jnp.exp(sol.params)\n",
    "\n",
    "def test_once(H = 3, sig = 0.5, lam = 0.01):\n",
    "    N=8192\n",
    "    AB_matrix = generate_matrix(1.0, 1.0, H)\n",
    "    Q_matrix = jnp.eye(H+1) * 1.0\n",
    "\n",
    "    a_cov = jnp.eye(H)*sig\n",
    "\n",
    "    R = AB_matrix.T @ Q_matrix @ AB_matrix\n",
    "    u, s, vh = jnp.linalg.svd(R)\n",
    "    sigma_eign = get_sigma_eign(s, lam, H, sig)\n",
    "    a_cov = vh.T @ jnp.diag(sigma_eign) @ vh\n",
    "\n",
    "    # a_cov = jnp.linalg.inv(2/lam*R)\n",
    "    print(s)\n",
    "    print(R)\n",
    "    print(a_cov)\n",
    "    print(jnp.linalg.det(a_cov))\n",
    "\n",
    "    def dynamic_fn(x, action):\n",
    "        # x = jnp.clip(0.9*x + 0.4 * jnp.clip(action, -1.0, 1.0), -2, 2)\n",
    "        x = 1.0*x + action\n",
    "        return x\n",
    "    \n",
    "    def reward_fn(t, x):\n",
    "        x_tar = jnp.sin(0.6*t)\n",
    "        reward = 1.0-jnp.abs(x - x_tar)\n",
    "        return reward\n",
    "\n",
    "    def get_next_a_mean(t, x, a_mean, rng):\n",
    "        # shift a_mean to the left by 1 and append the last element\n",
    "        a_mean = jnp.concatenate([a_mean[1:], a_mean[-1:]])\n",
    "\n",
    "        rng_act, rng = random.split(rng)\n",
    "        # sample actions with a_mean and a_cov\n",
    "        a_sampled = jax.vmap(lambda rng: random.multivariate_normal(rng, a_mean, a_cov))(random.split(rng, N)) # (N, H)\n",
    "\n",
    "        def rollout_fn(carry, action):\n",
    "            t, x = carry\n",
    "            x = dynamic_fn(x, action)\n",
    "            t = t + 1\n",
    "            reward = reward_fn(t, x)\n",
    "            return (t, x), reward\n",
    "\n",
    "        xx = jnp.repeat(x, N)\n",
    "        tt = jnp.repeat(t, N)\n",
    "        _, reward = jax.lax.scan(rollout_fn, (tt, xx), a_sampled.T)\n",
    "\n",
    "        cost = -jnp.sum(reward, axis=0)\n",
    "        cost_exp = jnp.exp(-(cost-jnp.min(cost)) / lam)\n",
    "        weight = cost_exp / jnp.sum(cost_exp)\n",
    "\n",
    "        a_mean = jnp.sum(a_sampled * weight[:, None], axis=0)\n",
    "\n",
    "        return a_mean, rng\n",
    "\n",
    "    def step_env(carry, unused):\n",
    "        t, x, a_mean, rng = carry\n",
    "        a_mean, rng = get_next_a_mean(t, x, a_mean, rng)\n",
    "        action = a_mean[0]\n",
    "        reward = reward_fn(t, x)\n",
    "        x = dynamic_fn(x, action)\n",
    "        t = t + 1\n",
    "        return (t, x, a_mean, rng), (x, reward)\n",
    "\n",
    "\n",
    "    def run_exp_once(rng):\n",
    "        x0 = 1.0\n",
    "        t0 = 0\n",
    "        a_mean = jnp.zeros(H)\n",
    "        carry = (t0, x0, a_mean, rng)\n",
    "        _, (x, reward) = jax.lax.scan(step_env, carry, jnp.arange(30))\n",
    "        return reward.mean()\n",
    "\n",
    "    rng = random.PRNGKey(0)\n",
    "    # run experiment for 4096 times\n",
    "    rewards = jax.vmap(jax.jit(run_exp_once))(random.split(rng, 4096))\n",
    "\n",
    "    return rewards.mean(), rewards.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_once(H=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
